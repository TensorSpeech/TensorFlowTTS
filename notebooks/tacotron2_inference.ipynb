{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensorflow-gpu==2.3.0rc1 bug to load_weight after call inference\n",
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipywidgets import Audio\n",
    "from tensorflow_tts.inference import AutoConfig\n",
    "from tensorflow_tts.inference import TFAutoModel\n",
    "from tensorflow_tts.processor.ljspeech import LJSpeechProcessor\n",
    "from tensorflow_tts.processor.ljspeech import symbols, _symbol_to_id\n",
    "from tensorflow_tts.utils import TFGriffinLim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config_path = \"../preprocess/ljspeech_preprocess.yaml\"\n",
    "ds_config = yaml.load(open(dataset_config_path), Loader=yaml.Loader)\n",
    "stats_path = \"../dump/stats.npy\"\n",
    "\n",
    "griffin_lim_tf = TFGriffinLim(dataset_config_path, stats_path)\n",
    "processor = LJSpeechProcessor(None, \"english_cleaners\")\n",
    "\n",
    "input_text = \"i love you so much.\"\n",
    "input_ids = processor.text_to_sequence(input_text)\n",
    "input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"../examples/tacotron2/conf/tacotron2.v1.yaml\")\n",
    "tacotron2 = TFAutoModel.from_pretrained(\n",
    "    config=config, \n",
    "    pretrained_path=None,\n",
    "    is_build=False, # don't build model if you want to save it to pb. (TF related bug)\n",
    "    name=\"tacotron2\"\n",
    ")\n",
    "\n",
    "tacotron2.setup_window(win_front=6, win_back=6)\n",
    "tacotron2.setup_maximum_iterations(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to serialized protocol buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(decoder_output, mel_outputs, stop_token_prediction, alignments) = tacotron2.inference(\n",
    "    input_ids=tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "    input_lengths=tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "    speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2.load_weights(\"../examples/tacotron2/checkpoints/model-120000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model into pb and do inference. Note that signatures should be a tf.function with input_signatures.\n",
    "tf.saved_model.save(tacotron2, \"./test_saved\", signatures=tacotron2.inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = tf.saved_model.load(\"./test_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Unless you work on a ship, it's unlikely that you use the word boatswain in everyday conversation, so it's understandably a tricky one. The word - which refers to a petty officer in charge of hull maintenance is not pronounced boats-wain Rather, it's bo-sun to reflect the salty pronunciation of sailors, as The Free Dictionary explains.\"\n",
    "input_ids = processor.text_to_sequence(input_text)\n",
    "input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(decoder_output, mel_outputs, stop_token_prediction, alignments) = tacotron2.inference(\n",
    "    tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "    tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "    tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(alignments[0], aspect=\"auto\", interpolation=\"none\", origin=\"lower\")\n",
    "fig.colorbar(im, pad=0.02, aspect=15, orientation=\"vertical\", ax=ax)\n",
    "ax.set_xlabel(\"Decoder timestep\")\n",
    "ax.set_ylabel(\"Encoder timestep\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs = tf.reshape(mel_outputs, [-1, config.n_mels])\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "im = ax.imshow(np.rot90(mel_outputs), aspect=\"auto\", interpolation=\"none\")\n",
    "fig.colorbar(im, pad=0.02, aspect=15, orientation=\"vertical\", ax=ax)\n",
    "ax.set_title(\"Predicted mel spectrogram\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_output = griffin_lim_tf(mel_outputs[tf.newaxis, :])\n",
    "tf_wav = tf.audio.encode_wav(gl_output[0, :, tf.newaxis], ds_config[\"sampling_rate\"])\n",
    "Audio(value=tf_wav.numpy(), autoplay=False, loop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with input of different shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The Commission further recommends that the Secret Service coordinate its planning as closely as possible with all of the Federal agencies from which it receives information.\"\n",
    "input_ids = processor.text_to_sequence(input_text)\n",
    "input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)  # eos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(decoder_output, mel_outputs, stop_token_prediction, alignments) = tacotron2.inference(\n",
    "    tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "    tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "    tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(alignments[0], aspect=\"auto\", interpolation=\"none\", origin=\"lower\")\n",
    "fig.colorbar(im, pad=0.02, aspect=15, orientation=\"vertical\", ax=ax)\n",
    "ax.set_xlabel(\"Decoder timestep\")\n",
    "ax.set_ylabel(\"Encoder timestep\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs = tf.reshape(mel_outputs, [-1, config.n_mels])\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "im = ax.imshow(np.rot90(mel_outputs), aspect=\"auto\", interpolation=\"none\")\n",
    "fig.colorbar(im, pad=0.02, aspect=15, orientation=\"vertical\", ax=ax)\n",
    "ax.set_title(\"Predicted mel spectrogram\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_output = griffin_lim_tf(mel_outputs[tf.newaxis, :])\n",
    "tf_wav = tf.audio.encode_wav(gl_output[0, :, tf.newaxis], ds_config[\"sampling_rate\"])\n",
    "Audio(value=tf_wav.numpy(), autoplay=False, loop=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
